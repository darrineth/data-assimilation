{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "https://github.com/thiery-lab/data-assimilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model is a [three-dimensional dynamical system developed as a simpified model of atmosphereic convection](https://en.wikipedia.org/wiki/Lorenz_system) by Lorenz [1] which is a classic example of chaotic non-periodic dynamics. A flow map $\\varphi : \\mathbb{R}_{\\geq 0} \\to (\\mathbb{R}^3 \\to \\mathbb{R}^3)$ is defined such that $\\boldsymbol{x}(\\tau) = \\varphi(\\tau)(\\boldsymbol{x}_0)$ where $\\boldsymbol{x}(\\tau), \\tau > 0$ is the solution to the initial value problem\n",
    "\\begin{equation}\n",
    "  \\frac{\\mathrm{d} x_0}{\\mathrm{d} \\tau} = \\sigma (x_1 - x_0), \\quad\n",
    "  \\frac{\\mathrm{d} x_1}{\\mathrm{d} \\tau} = x_0 (\\rho - x_2) - x_1, \\quad\n",
    "  \\frac{\\mathrm{d} x_2}{\\mathrm{d} \\tau} = x_0 x_1 - \\beta x_2 \\quad\n",
    "  \\text{and} \\quad \\boldsymbol{x}(0) = \\boldsymbol{x}_0.\n",
    "\\end{equation}\n",
    "\n",
    "Here we use the (standard) parameter values $\\rho = 28, \\sigma=10, \\beta=\\frac{8}{3}$ which exhibit chaotic dynamics. An implicit mid-point method is used to define an approximate flow map $\\tilde{\\varphi}(\\Delta) \\approx \\varphi(\\Delta)$ with time step $\\Delta = 0.005$ and $S=10$ time steps per state update. The state update is $\\boldsymbol{x}_t = \\bigcirc_{s=1}^S \\big(\\tilde{\\varphi}({\\Delta})\\big)(\\boldsymbol{x}_{t-1}) + \\boldsymbol{\\xi}_t$ with additive noise with distribution $\\boldsymbol{\\xi}_t \\sim \\mathcal{N}(\\mathbf{0}_3, 0.1^2 \\mathbb{I}_3)$ and initial state distribution $\\boldsymbol{x}_0 \\sim \\mathcal{N}(\\mathbf{1}_3, 0.5^2 \\mathbb{I}_3)$. The first $x_{0,t}$ component of the state is noisily observed $y_t = x_{0,t} + \\epsilon_t$, with additive Gaussian noise $\\epsilon_t \\sim \\mathcal{N}(0, 5^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "1. Lorenz, Edward Norton (1963). Deterministic nonperiodic flow. Journal of the Atmospheric Sciences. 20 (2): 130–141."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assimilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dapy.filters as filters\n",
    "from dapy.models import Lorenz1963Model\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'sigma': 10.,\n",
    "    'rho': 28.,\n",
    "    'beta': 8. / 3.,\n",
    "    'initial_state_mean': 1.,\n",
    "    'initial_state_std': 0.5,\n",
    "    'state_noise_std': 0.1,\n",
    "    'observation_function':  lambda x, t: x[..., 0:1],\n",
    "    'observation_noise_std': 5.,\n",
    "    'time_step': 0.1,\n",
    "    'num_integrator_step_per_update': 5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params['time_step']=0.05\n",
    "model_005 = Lorenz1963Model(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params['time_step']=0.01\n",
    "model_001 = Lorenz1963Model(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params['time_step']=0.001\n",
    "model_0001 = Lorenz1963Model(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent the same strech of time\\[0s, 50s) the indices vector has to be different for every model. Additional observations are calculated which will be later used in RC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_005_observations_count=1000\n",
    "observation_time_indices_005 = np.arange(int(2.5*_005_observations_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_001_observations_count=5000\n",
    "observation_time_indices_001 = np.arange(int(2.5*_001_observations_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_0001_observations_count=50000\n",
    "observation_time_indices_0001 = np.arange(int(2.5*_0001_observations_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "state_sequence_005, observation_sequence_005 = model_005.sample_state_and_observation_sequences(\n",
    "    rng, observation_time_indices_005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "state_sequence_001, observation_sequence_001 = model_001.sample_state_and_observation_sequences(\n",
    "    rng, observation_time_indices_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "state_sequence_0001, observation_sequence_0001 = model_0001.sample_state_and_observation_sequences(\n",
    "    rng, observation_time_indices_0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer state from observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, observation_time_indices, state_sequence=None, \n",
    "                 plot_particles=False, plot_region=True, \n",
    "                 particle_skip=2, trace_alpha=0.5):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(12, 9))\n",
    "    for i, ax in zip(range(3), axes):\n",
    "        ax.plot(results['state_mean_sequence'][:, i], 'g-', lw=1, label='Est. mean')\n",
    "        if plot_region:\n",
    "            ax.fill_between(\n",
    "                observation_time_indices,\n",
    "                results['state_mean_sequence'][:, i] - 3 * results['state_std_sequence'][:, i],\n",
    "                results['state_mean_sequence'][:, i] + 3 * results['state_std_sequence'][:, i],\n",
    "                alpha=0.25, color='g', label='Est. mean ± 3 standard deviation'\n",
    "            )\n",
    "        if plot_particles:\n",
    "            lines = ax.plot(\n",
    "                observation_time_indices, results['state_particles_sequence'][:, ::particle_skip, i], \n",
    "                'r-', lw=0.25, alpha=trace_alpha)\n",
    "            lines[0].set_label('Particles')\n",
    "        if state_sequence is not None:\n",
    "            ax.plot(observation_time_indices, state_sequence[:, i], 'k--', label='Truth')\n",
    "        ax.set_ylabel('$x_{0}$'.format(i))\n",
    "        ax.legend(loc='upper center', ncol=4)\n",
    "    ax.set_xlabel('Time index $t$')\n",
    "    fig.tight_layout()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lorenz(data, ground_truth=None):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={'projection': '3d'})\n",
    "    ax.plot(*data.T, '-', lw=0.5)\n",
    "    if ground_truth is not None:\n",
    "        ax.plot(*ground_truth.T, '-', lw=0.5)\n",
    "    ax.set_xlabel('$x_0$')\n",
    "    ax.set_ylabel('$x_1$')\n",
    "    ax.set_zlabel('$x_2$')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_metric(ground_truth, result):\n",
    "    return np.mean([sum(abs(np.subtract(*k)))/(i+1) for i, k in enumerate(zip(ground_truth, result))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Transform Kalman filter (deterministic square root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Kalman filter with deterministic matrix square root updates.\n",
    "\n",
    "The filtering distribution at each observation time index is approximated by alternating propagating an ensemble of state particles forward through time under the model dynamics and linearly transforming the ensemble according to a Monte Carlo estimate of the Kalman filter assimilation update due to the observations at the current time index. Here a 'square-root' ensemble Kalman filter assimilation update is used, which requires that the model has Gaussian observation noise with a known covariance, but compared to the 'perturbed observation' variant avoids the additional variance associated with sampling pseudo-observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "1. Bishop, C. H. Etherton, B. J. and  Majumdar, S. J. (2001). Adaptive sampling with the ensemble transform Kalman filter. Part I: Theoretical aspects.Mon. Wea. Rev., 129, 420–436.\n",
    "2. M. K. Tippett, J. L. Anderson, C. H. Bishop, T. M. Hamill, and J. S. Whitaker, Ensemble square root filters, Monthly Weather Review, 131 (2003), pp. 1485--1490."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etkf = filters.EnsembleTransformKalmanFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different values for num_particle\n",
    "# How does the result change?\n",
    "num_particle = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "results_etkf_005 = etkf.filter(\n",
    "    model_005, observation_sequence_005[:_005_observations_count], observation_time_indices_005[:_005_observations_count], \n",
    "    num_particle=num_particle, rng=rng, return_particles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_metric(state_sequence_005, results_etkf_005['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lorenz(results_etkf_005['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "results_etkf_005_half = etkf.filter(\n",
    "    model_005, observation_sequence_005[:int(_005_observations_count/2)], \n",
    "    observation_time_indices_005[:int(_005_observations_count/2)], \n",
    "    num_particle=num_particle, rng=rng, return_particles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metric(state_sequence_005[:int(_005_observations_count/2)], results_etkf_005_half['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lorenz(results_etkf_005_half['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "results_etkf_005_quarter = etkf.filter(\n",
    "    model_005, observation_sequence_005[:int(_005_observations_count/4)], \n",
    "    observation_time_indices_005[:int(_005_observations_count/4)], \n",
    "    num_particle=num_particle, rng=rng, return_particles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metric(state_sequence_005[:int(_005_observations_count/4)], results_etkf_005_quarter['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lorenz(results_etkf_005_quarter['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "results_etkf_001 = etkf.filter(\n",
    "    model_001, observation_sequence_001[:_001_observations_count], observation_time_indices_001[:_001_observations_count], \n",
    "    num_particle=num_particle, rng=rng, return_particles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metric(state_sequence_001, results_etkf_001['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lorenz(results_etkf_001['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "results_etkf_001_half = etkf.filter(\n",
    "    model_001, observation_sequence_001[:int(_001_observations_count/2)], \n",
    "    observation_time_indices_001[:int(_001_observations_count/2)], \n",
    "    num_particle=num_particle, rng=rng, return_particles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metric(state_sequence_001[:int(_001_observations_count/2)], results_etkf_001_half['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lorenz(results_etkf_001_half['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "results_etkf_001_quarter = etkf.filter(\n",
    "    model_001, observation_sequence_001[:int(_001_observations_count/4)], \n",
    "    observation_time_indices_001[:int(_001_observations_count/4)], \n",
    "    num_particle=num_particle, rng=rng, return_particles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metric(state_sequence_001[:int(_001_observations_count/4)], results_etkf_001_quarter['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lorenz(results_etkf_001_quarter['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "results_etkf_0001 = etkf.filter(\n",
    "    model_0001, observation_sequence_0001[:_0001_observations_count], observation_time_indices_0001[:_0001_observations_count], \n",
    "    num_particle=num_particle, rng=rng, return_particles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metric(state_sequence_0001, results_etkf_0001['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lorenz(results_etkf_0001['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "results_etkf_0001_half = etkf.filter(\n",
    "    model_0001, observation_sequence_0001[:int(_0001_observations_count/2)], \n",
    "    observation_time_indices_0001[:int(_0001_observations_count/2)], \n",
    "    num_particle=num_particle, rng=rng, return_particles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_metric(state_sequence_0001[:int(_0001_observations_count/2)], results_etkf_0001_half['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lorenz(results_etkf_0001_half['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "results_etkf_0001_quarter = etkf.filter(\n",
    "    model_0001, observation_sequence_0001[:int(_0001_observations_count/4)], \n",
    "    observation_time_indices_0001[:int(_0001_observations_count/4)], \n",
    "    num_particle=num_particle, rng=rng, return_particles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metric(state_sequence_0001[:int(_0001_observations_count/4)], results_etkf_0001_quarter['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lorenz(results_etkf_0001_quarter['state_mean_sequence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reservoir computing\n",
    "\n",
    "Reservoir computing is a framework for computation derived from recurrent neural network theory that maps input signals into higher dimensional computational spaces through the dynamics of a fixed, non-linear system called a reservoir. After the input signal is fed into the reservoir, which is treated as a \"black box,\" a simple readout mechanism is trained to read the state of the reservoir and map it to the desired output. The first key benefit of this framework is that training is performed only at the readout stage, as the reservoir dynamics are fixed. The second is that the computational power of naturally available systems, both classical and quantum mechanical, can be utilized to reduce the effective computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "1. Tanaka, Gouhei; Yamane, Toshiyuki; Héroux, Jean Benoit; Nakane, Ryosho; Kanazawa, Naoki; Takeda, Seiji; Numata, Hidetoshi; Nakano, Daiju; Hirose, Akira (2019). \"Recent advances in physical reservoir computing: A review\". Neural Networks. 115: 100–123. doi:10.1016/j.neunet.2019.03.005. ISSN 0893-6080. PMID 30981085.\n",
    "2. Röhm, André; Lüdge, Kathy (2018-08-03). \"Multiplexed networks: reservoir computing with virtual and real nodes\". Journal of Physics Communications. 2 (8): 085007. Bibcode:2018JPhCo...2h5007R. doi:10.1088/2399-6528/aad56d. ISSN 2399-6528"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echo state network\n",
    "\n",
    "The echo state network (ESN) is a type of reservoir computer that uses a recurrent neural network with a sparsely connected hidden layer (with typically 1% connectivity). The connectivity and weights of hidden neurons are fixed and randomly assigned. The weights of output neurons can be learned so that the network can produce or reproduce specific temporal patterns. The main interest of this network is that although its behaviour is non-linear, the only weights that are modified during training are for the synapses that connect the hidden neurons to output neurons. Thus, the error function is quadratic with respect to the parameter vector and can be differentiated easily to a linear system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/tmp/pyESN')\n",
    "from pyESN import ESN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lorenz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predictions(esn, ground_truth, learning_length): \n",
    "    pred_training = esn.fit(np.ones(learning_length), ground_truth[:learning_length])\n",
    "    \n",
    "    prediction_length=int(learning_length/50)\n",
    "    prediction=esn.predict(np.ones(prediction_length))\n",
    "    prediction_ground_truth=ground_truth[learning_length:learning_length+prediction_length] \n",
    "    \n",
    "    plot_lorenz(prediction, prediction_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Set the number of output layers\n",
    "# Experiment with different values for n_reservoir\n",
    "# How does the result change?\n",
    "esn = ESN(n_inputs = 1,\n",
    "          n_outputs = 3,\n",
    "          n_reservoir = 1024,\n",
    "          spectral_radius = 1.5,\n",
    "          random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calculate_predictions(esn, state_sequence_005, _005_observations_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "#TODO: Show prediction result on plot\n",
    "ax.plot(prediction[:,0],prediction[:,1],prediction[:,2], lw=0.5)\n",
    "# ax.plot(data[future:,0], data[future:,1], data[future:,2], lw=0.5)\n",
    "ax.set_xlabel(\"X Axis\")\n",
    "ax.set_ylabel(\"Y Axis\")\n",
    "ax.set_zlabel(\"Z Axis\")\n",
    "ax.set_title(\"Lorenz Attractor\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
